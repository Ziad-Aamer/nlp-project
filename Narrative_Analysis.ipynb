{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "IBf_7vjqHIvI",
      "metadata": {
        "id": "IBf_7vjqHIvI"
      },
      "source": [
        "# Code Pre-run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:16:56.684051Z",
          "start_time": "2025-01-01T13:16:53.970202Z"
        },
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Bonn Uni\\bonn-uni\\NLP\\project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgo\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments, PreTrainedModel, AutoConfig\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "XyfnBzObGLTR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XyfnBzObGLTR",
        "outputId": "12c896bb-e215-4947-be0e-69e0b46ef053"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sanity Check for device usage\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.get_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "TteGdlxxk07M",
      "metadata": {
        "id": "TteGdlxxk07M"
      },
      "outputs": [],
      "source": [
        "# Optional setting to handle wandb trigger\n",
        "os.environ['WANDB_DISABLED'] = 'true'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AmL483E4HRfy",
      "metadata": {
        "id": "AmL483E4HRfy"
      },
      "source": [
        "# Global Declarations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ddcb4fda71077ca3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:17:00.581609Z",
          "start_time": "2025-01-01T13:17:00.578432Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddcb4fda71077ca3",
        "outputId": "ad0dab6d-2a28-4bf8-8d3b-2d0aff9d55a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "# Global Configuration\n",
        "drive_path = ''\n",
        "annotation_files = {\n",
        "    \"EN\": drive_path + \"EN/subtask-2-annotations.txt\",\n",
        "    \"PT\": drive_path + \"PT/subtask-2-annotations.txt\",\n",
        "}\n",
        "raw_documents_dirs = {\n",
        "    \"EN\": drive_path + \"EN/raw-documents\",\n",
        "    \"PT\": drive_path + \"PT/raw-documents\",\n",
        "}\n",
        "max_len = 512\n",
        "batch_size = 8\n",
        "num_epochs = 20\n",
        "pretrained_model_name = \"bert-base-multilingual-cased\"  # Use multilingual model\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "\n",
        "# Set a dark theme\n",
        "mpl.rcParams.update({\n",
        "    'axes.facecolor': '#2E2E2E',\n",
        "    'axes.edgecolor': 'white',\n",
        "    'axes.labelcolor': 'white',\n",
        "    'xtick.color': 'white',\n",
        "    'ytick.color': 'white',\n",
        "    'text.color': 'white',\n",
        "    'figure.facecolor': '#2E2E2E',\n",
        "    'grid.color': '#444444',\n",
        "    'legend.facecolor': '#444444',\n",
        "    'legend.edgecolor': 'white'\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "P3AAmKd2gfaj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3AAmKd2gfaj",
        "outputId": "4c86106a-a273-4eae-974c-c51efef0910f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sanity check for file location\n",
        "os.path.isdir(raw_documents_dirs[\"EN\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BfwEqTA4G0ud",
      "metadata": {
        "id": "BfwEqTA4G0ud"
      },
      "source": [
        "# Dataset Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "f8a9d3756683030b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:16:58.601457Z",
          "start_time": "2025-01-01T13:16:58.596100Z"
        },
        "id": "f8a9d3756683030b"
      },
      "outputs": [],
      "source": [
        "# Dataset class for handling text and labels\n",
        "class NarrativeDataset(Dataset):\n",
        "    def __init__(self, texts, narrative_labels, sub_narrative_labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.narrative_labels = narrative_labels\n",
        "        self.sub_narrative_labels = sub_narrative_labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        if self.sub_narrative_labels is None:\n",
        "            labels = torch.tensor(self.narrative_labels[idx], dtype=torch.float)\n",
        "        elif self.narrative_labels is None:\n",
        "            labels = torch.tensor(self.sub_narrative_labels[idx], dtype=torch.float)\n",
        "        else:\n",
        "            labels = torch.cat(\n",
        "            [\n",
        "                torch.tensor(self.narrative_labels[idx], dtype=torch.float),\n",
        "                torch.tensor(self.sub_narrative_labels[idx], dtype=torch.float),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": labels,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "90085704eaab9871",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:17:00.048548Z",
          "start_time": "2025-01-01T13:17:00.043487Z"
        },
        "id": "90085704eaab9871"
      },
      "outputs": [],
      "source": [
        "# Updated preprocess_data function to handle multilingual data\n",
        "def preprocess_data(annotation_file, raw_documents_dir):\n",
        "    data = pd.read_csv(\n",
        "        annotation_file,\n",
        "        sep=\"\\t\",\n",
        "        names=[\"filename\", \"narratives\", \"sub_narratives\"],\n",
        "    )\n",
        "\n",
        "    def read_file(filename):\n",
        "        with open(os.path.join(raw_documents_dir, filename), \"r\", encoding=\"utf-8\") as file:\n",
        "            return file.read()\n",
        "\n",
        "    data[\"text\"] = data[\"filename\"].apply(read_file)\n",
        "\n",
        "    def process_labels(label_string):\n",
        "        if isinstance(label_string, str):\n",
        "            return [label.strip() for label in label_string.split(\";\") if label.strip()]\n",
        "        else:\n",
        "            return [\"Other\"]\n",
        "\n",
        "    data[\"narratives\"] = data[\"narratives\"].apply(process_labels)\n",
        "    data[\"sub_narratives\"] = data[\"sub_narratives\"].apply(process_labels)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "661afc62a9203ddc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:23:50.746571Z",
          "start_time": "2025-01-01T13:23:50.732874Z"
        },
        "id": "661afc62a9203ddc"
      },
      "outputs": [],
      "source": [
        "# Load and combine datasets\n",
        "datasets = []\n",
        "for lang, annotation_file in annotation_files.items():\n",
        "    raw_documents_dir = raw_documents_dirs[lang]\n",
        "    datasets.append(preprocess_data(annotation_file, raw_documents_dir))\n",
        "data = pd.concat(datasets).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# MultiLabelBinarizer for narratives and sub-narratives\n",
        "narrative_mlb = MultiLabelBinarizer()\n",
        "sub_narrative_mlb = MultiLabelBinarizer()\n",
        "\n",
        "y_narratives = narrative_mlb.fit_transform(data[\"narratives\"])\n",
        "y_sub_narratives = sub_narrative_mlb.fit_transform(data[\"sub_narratives\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "adNii0cWH_ZO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adNii0cWH_ZO",
        "outputId": "41ea20ca-d946-4df0-8bfd-9bfcef010871"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 0, 0]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sanity check for binarizer of narratives\n",
        "y_narratives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "A5Nx5gPGKKpu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5Nx5gPGKKpu",
        "outputId": "9538b93c-354b-4079-ecff-c3d3e053e61d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sanity check for binarizer of subnarratives\n",
        "y_sub_narratives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "3bb88705631f993c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:17:01.960157Z",
          "start_time": "2025-01-01T13:17:01.391761Z"
        },
        "id": "3bb88705631f993c"
      },
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "train_texts, test_texts, y_train_narratives, y_test_narratives, y_train_sub, y_test_sub = train_test_split(\n",
        "    data[\"text\"], y_narratives, y_sub_narratives, test_size=0.2, random_state=42\n",
        ")\n",
        "val_texts, test_texts, y_val_narratives, y_test_narratives, y_val_sub, y_test_sub = train_test_split(\n",
        "    test_texts, y_test_narratives, y_test_sub, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Tokenizer and model initialization\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TJgMHCzgI7bq",
      "metadata": {
        "id": "TJgMHCzgI7bq"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "2887342faf2df720",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:16:59.281872Z",
          "start_time": "2025-01-01T13:16:59.278093Z"
        },
        "id": "2887342faf2df720"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    logits = pred.predictions\n",
        "\n",
        "    # Apply threshold to logits to get binary predictions\n",
        "    preds = (logits > 0).astype(int)\n",
        "\n",
        "    # Compute precision, recall, f1\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=\"weighted\", zero_division=0\n",
        "    )\n",
        "\n",
        "    # Compute multi-label accuracy\n",
        "    accuracy = (preds == labels).mean()  # Fraction of correctly predicted labels\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KpJLlHFmInGV",
      "metadata": {
        "id": "KpJLlHFmInGV"
      },
      "source": [
        "# Narrative Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "jyjo_7_2Ij5F",
      "metadata": {
        "id": "jyjo_7_2Ij5F"
      },
      "outputs": [],
      "source": [
        "# Create narratives datasets\n",
        "train_narrative_dataset = NarrativeDataset(\n",
        "    train_texts.tolist(), y_train_narratives, None, tokenizer, max_len\n",
        ")\n",
        "val_narrative_dataset = NarrativeDataset(\n",
        "    val_texts.tolist(), y_val_narratives, None, tokenizer, max_len\n",
        ")\n",
        "test_narrative_dataset = NarrativeDataset(\n",
        "    test_texts.tolist(), y_test_narratives, None, tokenizer, max_len\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9204eb1640c7ddb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:16:57.947432Z",
          "start_time": "2025-01-01T13:16:57.944164Z"
        },
        "id": "9204eb1640c7ddb"
      },
      "outputs": [],
      "source": [
        "class NarrativeClassificationModel(PreTrainedModel):\n",
        "    def __init__(self, pretrained_model_name, num_narrative_labels):\n",
        "        config = AutoConfig.from_pretrained(pretrained_model_name)\n",
        "        config.num_labels = num_narrative_labels\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.bert = AutoModel.from_pretrained(pretrained_model_name)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, config.num_labels)\n",
        "        self.loss_fn = BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = self.classifier(outputs.last_hidden_state[:, 0, :])  # Use [CLS] token embeddings\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "\n",
        "        return SequenceClassifierOutput(loss=loss, logits=logits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "GvnNZ9qrIQTE",
      "metadata": {
        "id": "GvnNZ9qrIQTE"
      },
      "outputs": [],
      "source": [
        "# Create narrative model\n",
        "narrative_model = NarrativeClassificationModel(\n",
        "    pretrained_model_name,\n",
        "    num_narrative_labels=y_train_narratives.shape[1],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "64dd5118feb21ce6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:17:43.648145Z",
          "start_time": "2025-01-01T13:17:03.387281Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "64dd5118feb21ce6",
        "outputId": "c7522957-99a8-45d8-dece-6ad56fc4f589"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1600' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1600/1600 29:38, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.236100</td>\n",
              "      <td>0.227861</td>\n",
              "      <td>0.909659</td>\n",
              "      <td>0.171987</td>\n",
              "      <td>0.145455</td>\n",
              "      <td>0.155146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.194200</td>\n",
              "      <td>0.218538</td>\n",
              "      <td>0.909659</td>\n",
              "      <td>0.265486</td>\n",
              "      <td>0.248485</td>\n",
              "      <td>0.239919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.164500</td>\n",
              "      <td>0.210208</td>\n",
              "      <td>0.914205</td>\n",
              "      <td>0.397596</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.329145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.160800</td>\n",
              "      <td>0.188140</td>\n",
              "      <td>0.922727</td>\n",
              "      <td>0.519531</td>\n",
              "      <td>0.296970</td>\n",
              "      <td>0.358610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.130300</td>\n",
              "      <td>0.204079</td>\n",
              "      <td>0.917614</td>\n",
              "      <td>0.488657</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.354454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.109000</td>\n",
              "      <td>0.193636</td>\n",
              "      <td>0.922727</td>\n",
              "      <td>0.707456</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>0.513662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.098100</td>\n",
              "      <td>0.201660</td>\n",
              "      <td>0.923864</td>\n",
              "      <td>0.656111</td>\n",
              "      <td>0.448485</td>\n",
              "      <td>0.478995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.074300</td>\n",
              "      <td>0.190836</td>\n",
              "      <td>0.928977</td>\n",
              "      <td>0.692165</td>\n",
              "      <td>0.406061</td>\n",
              "      <td>0.482555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.207096</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.638870</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.478179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.051400</td>\n",
              "      <td>0.189950</td>\n",
              "      <td>0.932386</td>\n",
              "      <td>0.686912</td>\n",
              "      <td>0.515152</td>\n",
              "      <td>0.556204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.042900</td>\n",
              "      <td>0.193426</td>\n",
              "      <td>0.932955</td>\n",
              "      <td>0.708484</td>\n",
              "      <td>0.515152</td>\n",
              "      <td>0.562237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.043000</td>\n",
              "      <td>0.197396</td>\n",
              "      <td>0.931250</td>\n",
              "      <td>0.679950</td>\n",
              "      <td>0.478788</td>\n",
              "      <td>0.533778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.034300</td>\n",
              "      <td>0.203946</td>\n",
              "      <td>0.926705</td>\n",
              "      <td>0.651153</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>0.520432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.025300</td>\n",
              "      <td>0.199809</td>\n",
              "      <td>0.931818</td>\n",
              "      <td>0.702486</td>\n",
              "      <td>0.503030</td>\n",
              "      <td>0.548478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.021700</td>\n",
              "      <td>0.205759</td>\n",
              "      <td>0.929545</td>\n",
              "      <td>0.695715</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>0.519072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.028300</td>\n",
              "      <td>0.203832</td>\n",
              "      <td>0.928409</td>\n",
              "      <td>0.663867</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.527077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.024300</td>\n",
              "      <td>0.210408</td>\n",
              "      <td>0.927841</td>\n",
              "      <td>0.675334</td>\n",
              "      <td>0.478788</td>\n",
              "      <td>0.518196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.024700</td>\n",
              "      <td>0.207444</td>\n",
              "      <td>0.931250</td>\n",
              "      <td>0.699941</td>\n",
              "      <td>0.503030</td>\n",
              "      <td>0.542056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.211509</td>\n",
              "      <td>0.928977</td>\n",
              "      <td>0.696498</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.525450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.024000</td>\n",
              "      <td>0.210821</td>\n",
              "      <td>0.928977</td>\n",
              "      <td>0.684677</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.526975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1600, training_loss=0.0819653993844986, metrics={'train_runtime': 1779.5961, 'train_samples_per_second': 7.181, 'train_steps_per_second': 0.899, 'total_flos': 3363163108761600.0, 'train_loss': 0.0819653993844986, 'epoch': 20.0})"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create narrative model trainer\n",
        "narrative_trainer = Trainer(\n",
        "    model=narrative_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_narrative_dataset,\n",
        "    eval_dataset=val_narrative_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train and evaluate\n",
        "narrative_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "bf48c4c2280052d5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:17:46.941092Z",
          "start_time": "2025-01-01T13:17:46.582678Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "bf48c4c2280052d5",
        "outputId": "cf3d5762-4f1e-4340-e402-aff939b65271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.16147944331169128,\n",
              " 'eval_accuracy': 0.9460227272727273,\n",
              " 'eval_precision': 0.6261813350048644,\n",
              " 'eval_recall': 0.5714285714285714,\n",
              " 'eval_f1': 0.5881386010929698,\n",
              " 'eval_runtime': 2.4445,\n",
              " 'eval_samples_per_second': 32.726,\n",
              " 'eval_steps_per_second': 4.091,\n",
              " 'epoch': 20.0}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "print(\"Evaluating on test set...\")\n",
        "results = narrative_trainer.evaluate(test_narrative_dataset)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "7iSGlNDK4cAS",
      "metadata": {
        "id": "7iSGlNDK4cAS"
      },
      "outputs": [],
      "source": [
        "# Save narrative model for more downstream use\n",
        "with open('narrative_model.pkl','wb') as f:\n",
        "    pickle.dump(narrative_model,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "D8o_LszE6Amz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "D8o_LszE6Amz",
        "outputId": "854e8342-c284-4e1d-d29f-54ffd6deeea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.16147944331169128,\n",
              " 'eval_model_preparation_time': 0.0049,\n",
              " 'eval_accuracy': 0.9460227272727273,\n",
              " 'eval_precision': 0.6261813350048644,\n",
              " 'eval_recall': 0.5714285714285714,\n",
              " 'eval_f1': 0.5881386010929698,\n",
              " 'eval_runtime': 2.4665,\n",
              " 'eval_samples_per_second': 32.435,\n",
              " 'eval_steps_per_second': 4.054}"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sanity Check for narrative_model store\n",
        "\n",
        "with open('narrative_model.pkl', 'rb') as f:\n",
        "    n_model = pickle.load(f)\n",
        "\n",
        "n_trainer = Trainer(\n",
        "    model=n_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_narrative_dataset,\n",
        "    eval_dataset=val_narrative_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating on test set...\")\n",
        "results = n_trainer.evaluate(test_narrative_dataset)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xUEWgatNJdNS",
      "metadata": {
        "id": "xUEWgatNJdNS"
      },
      "source": [
        "## Narrative Model Output Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45c13697776c1db4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:17:47.917376Z",
          "start_time": "2025-01-01T13:17:47.914812Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "45c13697776c1db4",
        "outputId": "344cdf55-55b2-45a9-cf0a-4e1e14746452"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('URW: Blaming the war on others rather than the invader', 'URW: Russia is the Victim')\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy', 'URW: Speculating war outcomes')\n",
            "Actual Labels: ('URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy', 'URW: Praise of Russia', 'URW: Speculating war outcomes')\n",
            "Matched Labels: {'URW: Speculating war outcomes', 'URW: Discrediting the West, Diplomacy', 'URW: Discrediting Ukraine'}\n",
            "Matched Percentage: 75.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Amplifying war-related fears', 'URW: Discrediting the West, Diplomacy')\n",
            "Actual Labels: ('URW: Discrediting the West, Diplomacy', 'URW: Negative Consequences for the West')\n",
            "Matched Labels: {'URW: Discrediting the West, Diplomacy'}\n",
            "Matched Percentage: 50.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('CC: Controversy about green technologies', 'CC: Criticism of climate movement', 'CC: Green policies are geopolitical instruments')\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting Ukraine', 'URW: Praise of Russia', 'URW: Russia is the Victim')\n",
            "Actual Labels: ('URW: Discrediting Ukraine',)\n",
            "Matched Labels: {'URW: Discrediting Ukraine'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Amplifying Climate Fears', 'CC: Criticism of institutions and authorities')\n",
            "Actual Labels: ('CC: Criticism of institutions and authorities',)\n",
            "Matched Labels: {'CC: Criticism of institutions and authorities'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy', 'URW: Russia is the Victim')\n",
            "Actual Labels: ('URW: Discrediting Ukraine',)\n",
            "Matched Labels: {'URW: Discrediting Ukraine'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Criticism of institutions and authorities',)\n",
            "Actual Labels: ('CC: Criticism of climate policies',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('CC: Amplifying Climate Fears',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Blaming the war on others rather than the invader', 'URW: Russia is the Victim')\n",
            "Actual Labels: ('URW: Blaming the war on others rather than the invader', 'URW: Praise of Russia', 'URW: Russia is the Victim')\n",
            "Matched Labels: {'URW: Blaming the war on others rather than the invader', 'URW: Russia is the Victim'}\n",
            "Matched Percentage: 66.67%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Amplifying Climate Fears',)\n",
            "Actual Labels: ('CC: Amplifying Climate Fears',)\n",
            "Matched Labels: {'CC: Amplifying Climate Fears'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Amplifying Climate Fears',)\n",
            "Actual Labels: ('CC: Amplifying Climate Fears',)\n",
            "Matched Labels: {'CC: Amplifying Climate Fears'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Criticism of institutions and authorities', 'CC: Hidden plots by secret schemes of powerful groups')\n",
            "Actual Labels: ('CC: Hidden plots by secret schemes of powerful groups',)\n",
            "Matched Labels: {'CC: Hidden plots by secret schemes of powerful groups'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Blaming the war on others rather than the invader', 'URW: Discrediting Ukraine')\n",
            "Actual Labels: ('URW: Blaming the war on others rather than the invader', 'URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy')\n",
            "Matched Labels: {'URW: Blaming the war on others rather than the invader', 'URW: Discrediting Ukraine'}\n",
            "Matched Percentage: 66.67%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting the West, Diplomacy',)\n",
            "Actual Labels: ('URW: Discrediting the West, Diplomacy', 'URW: Overpraising the West')\n",
            "Matched Labels: {'URW: Discrediting the West, Diplomacy'}\n",
            "Matched Percentage: 50.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Criticism of institutions and authorities',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting the West, Diplomacy',)\n",
            "Actual Labels: ('URW: Amplifying war-related fears',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Criticism of institutions and authorities',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy')\n",
            "Actual Labels: ('URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy')\n",
            "Matched Labels: {'URW: Discrediting the West, Diplomacy', 'URW: Discrediting Ukraine'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Amplifying Climate Fears', 'CC: Criticism of institutions and authorities')\n",
            "Actual Labels: ('CC: Amplifying Climate Fears', 'CC: Criticism of climate policies', 'CC: Criticism of institutions and authorities')\n",
            "Matched Labels: {'CC: Criticism of institutions and authorities', 'CC: Amplifying Climate Fears'}\n",
            "Matched Percentage: 66.67%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Amplifying Climate Fears',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Criticism of institutions and authorities',)\n",
            "Actual Labels: ('CC: Amplifying Climate Fears',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy', 'URW: Russia is the Victim')\n",
            "Actual Labels: ('URW: Blaming the war on others rather than the invader', 'URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy', 'URW: Praise of Russia', 'URW: Russia is the Victim')\n",
            "Matched Labels: {'URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy', 'URW: Russia is the Victim'}\n",
            "Matched Percentage: 60.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Amplifying Climate Fears', 'CC: Criticism of institutions and authorities')\n",
            "Actual Labels: ('CC: Amplifying Climate Fears', 'CC: Criticism of institutions and authorities')\n",
            "Matched Labels: {'CC: Criticism of institutions and authorities', 'CC: Amplifying Climate Fears'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('URW: Amplifying war-related fears', 'URW: Blaming the war on others rather than the invader')\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('CC: Amplifying Climate Fears', 'CC: Criticism of institutions and authorities')\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Amplifying Climate Fears', 'CC: Criticism of institutions and authorities')\n",
            "Actual Labels: ('CC: Amplifying Climate Fears', 'CC: Criticism of institutions and authorities')\n",
            "Matched Labels: {'CC: Criticism of institutions and authorities', 'CC: Amplifying Climate Fears'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting the West, Diplomacy',)\n",
            "Actual Labels: ('URW: Discrediting the West, Diplomacy',)\n",
            "Matched Labels: {'URW: Discrediting the West, Diplomacy'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Amplifying war-related fears',)\n",
            "Actual Labels: ('URW: Amplifying war-related fears', 'URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy')\n",
            "Matched Labels: {'URW: Amplifying war-related fears'}\n",
            "Matched Percentage: 33.33%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting Ukraine',)\n",
            "Actual Labels: ('URW: Discrediting Ukraine', 'URW: Russia is the Victim')\n",
            "Matched Labels: {'URW: Discrediting Ukraine'}\n",
            "Matched Percentage: 50.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Amplifying war-related fears', 'URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy')\n",
            "Actual Labels: ('URW: Amplifying war-related fears', 'URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy', 'URW: Negative Consequences for the West', 'URW: Overpraising the West', 'URW: Praise of Russia', 'URW: Speculating war outcomes')\n",
            "Matched Labels: {'URW: Amplifying war-related fears', 'URW: Discrediting the West, Diplomacy', 'URW: Discrediting Ukraine'}\n",
            "Matched Percentage: 42.86%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('URW: Hidden plots by secret schemes of powerful groups',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Amplifying Climate Fears',)\n",
            "Actual Labels: ('CC: Amplifying Climate Fears',)\n",
            "Matched Labels: {'CC: Amplifying Climate Fears'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('URW: Amplifying war-related fears', 'URW: Discrediting the West, Diplomacy', 'URW: Negative Consequences for the West', 'URW: Overpraising the West')\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Criticism of institutions and authorities',)\n",
            "Actual Labels: ('CC: Criticism of institutions and authorities',)\n",
            "Matched Labels: {'CC: Criticism of institutions and authorities'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy')\n",
            "Actual Labels: ('URW: Discrediting the West, Diplomacy',)\n",
            "Matched Labels: {'URW: Discrediting the West, Diplomacy'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('CC: Criticism of climate movement', 'CC: Criticism of institutions and authorities')\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting Ukraine', 'URW: Praise of Russia')\n",
            "Actual Labels: ('URW: Discrediting Ukraine', 'URW: Praise of Russia')\n",
            "Matched Labels: {'URW: Discrediting Ukraine', 'URW: Praise of Russia'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Amplifying war-related fears', 'URW: Discrediting the West, Diplomacy')\n",
            "Actual Labels: ('URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy')\n",
            "Matched Labels: {'URW: Discrediting the West, Diplomacy'}\n",
            "Matched Percentage: 50.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Blaming the war on others rather than the invader', 'URW: Discrediting Ukraine', 'URW: Praise of Russia', 'URW: Russia is the Victim')\n",
            "Actual Labels: ('URW: Discrediting Ukraine', 'URW: Praise of Russia', 'URW: Russia is the Victim')\n",
            "Matched Labels: {'URW: Discrediting Ukraine', 'URW: Russia is the Victim', 'URW: Praise of Russia'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Amplifying Climate Fears', 'CC: Criticism of institutions and authorities')\n",
            "Actual Labels: ('CC: Amplifying Climate Fears', 'CC: Criticism of institutions and authorities')\n",
            "Matched Labels: {'CC: Criticism of institutions and authorities', 'CC: Amplifying Climate Fears'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('URW: Amplifying war-related fears', 'URW: Blaming the war on others rather than the invader', 'URW: Discrediting the West, Diplomacy')\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Praise of Russia', 'URW: Russia is the Victim')\n",
            "Actual Labels: ('URW: Blaming the war on others rather than the invader', 'URW: Discrediting Ukraine', 'URW: Praise of Russia')\n",
            "Matched Labels: {'URW: Praise of Russia'}\n",
            "Matched Percentage: 33.33%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('CC: Amplifying Climate Fears',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy', 'URW: Praise of Russia')\n",
            "Actual Labels: ('URW: Praise of Russia',)\n",
            "Matched Labels: {'URW: Praise of Russia'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Praise of Russia',)\n",
            "Actual Labels: ('URW: Discrediting Ukraine',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Criticism of climate policies', 'CC: Criticism of institutions and authorities', 'CC: Hidden plots by secret schemes of powerful groups')\n",
            "Actual Labels: ('CC: Criticism of climate policies', 'CC: Criticism of institutions and authorities')\n",
            "Matched Labels: {'CC: Criticism of climate policies', 'CC: Criticism of institutions and authorities'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting the West, Diplomacy',)\n",
            "Actual Labels: ('URW: Overpraising the West',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Amplifying war-related fears', 'URW: Discrediting Ukraine', 'URW: Russia is the Victim')\n",
            "Actual Labels: ('URW: Amplifying war-related fears', 'URW: Blaming the war on others rather than the invader', 'URW: Discrediting Ukraine', 'URW: Russia is the Victim')\n",
            "Matched Labels: {'URW: Discrediting Ukraine', 'URW: Amplifying war-related fears', 'URW: Russia is the Victim'}\n",
            "Matched Percentage: 75.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Blaming the war on others rather than the invader', 'URW: Russia is the Victim')\n",
            "Actual Labels: ('URW: Russia is the Victim',)\n",
            "Matched Labels: {'URW: Russia is the Victim'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('URW: Speculating war outcomes',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('CC: Criticism of climate movement',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('URW: Amplifying war-related fears', 'URW: Discrediting Ukraine', 'URW: Distrust towards Media', 'URW: Praise of Russia', 'URW: Russia is the Victim')\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting the West, Diplomacy', 'URW: Russia is the Victim')\n",
            "Actual Labels: ('URW: Negative Consequences for the West', 'URW: Overpraising the West')\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('URW: Amplifying war-related fears',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('CC: Criticism of climate policies',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting the West, Diplomacy',)\n",
            "Actual Labels: ('URW: Amplifying war-related fears', 'URW: Discrediting the West, Diplomacy')\n",
            "Matched Labels: {'URW: Discrediting the West, Diplomacy'}\n",
            "Matched Percentage: 50.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Criticism of institutions and authorities',)\n",
            "Actual Labels: ('CC: Criticism of institutions and authorities', 'CC: Questioning the measurements and science')\n",
            "Matched Labels: {'CC: Criticism of institutions and authorities'}\n",
            "Matched Percentage: 50.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy', 'URW: Russia is the Victim')\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Discrediting the West, Diplomacy',)\n",
            "Actual Labels: ('URW: Discrediting the West, Diplomacy', 'URW: Russia is the Victim')\n",
            "Matched Labels: {'URW: Discrediting the West, Diplomacy'}\n",
            "Matched Percentage: 50.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('CC: Amplifying Climate Fears',)\n",
            "Actual Labels: ('CC: Amplifying Climate Fears',)\n",
            "Matched Labels: {'CC: Amplifying Climate Fears'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('Other',)\n",
            "Actual Labels: ('Other',)\n",
            "Matched Labels: {'Other'}\n",
            "Matched Percentage: 100.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ()\n",
            "Actual Labels: ('CC: Downplaying climate change', 'CC: Questioning the measurements and science')\n",
            "Matched Labels: set()\n",
            "Matched Percentage: 0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Predicted Labels: ('URW: Amplifying war-related fears', 'URW: Discrediting the West, Diplomacy')\n",
            "Actual Labels: ('URW: Amplifying war-related fears', 'URW: Praise of Russia', 'URW: Russia is the Victim')\n",
            "Matched Labels: {'URW: Amplifying war-related fears'}\n",
            "Matched Percentage: 33.33%\n",
            "--------------------------------------------------\n",
            "\n",
            "Final Score: 49.29%\n"
          ]
        }
      ],
      "source": [
        "# Get the predicted labels for the test set\n",
        "predictions = narrative_trainer.predict(test_narrative_dataset)\n",
        "predicted_logits = predictions.predictions\n",
        "predicted_labels = (predicted_logits > 0).astype(int)\n",
        "\n",
        "# Convert the binary matrix back to label names\n",
        "predicted_label_names = narrative_mlb.inverse_transform(predicted_labels)\n",
        "actual_label_names = narrative_mlb.inverse_transform(y_test_narratives)\n",
        "\n",
        "# Initialize counters for the final score\n",
        "total_labels = 0\n",
        "correct_labels = 0\n",
        "\n",
        "# Print the test texts with their predicted and actual labels\n",
        "for text, predicted_labels, actual_labels in zip(test_texts, predicted_label_names, actual_label_names):\n",
        "    matched_labels = set(predicted_labels) & set(actual_labels)\n",
        "    matched_percentage = len(matched_labels) / len(actual_labels) * 100 if actual_labels else 0\n",
        "    total_labels += len(actual_labels)\n",
        "    correct_labels += len(matched_labels)\n",
        "\n",
        "    print(f\"Predicted Labels: {predicted_labels}\\nActual Labels: {actual_labels}\")\n",
        "    print(f\"Matched Labels: {matched_labels}\\nMatched Percentage: {matched_percentage:.2f}%\")\n",
        "    print(\"--------------------------------------------------\\n\")\n",
        "\n",
        "# Calculate the final score\n",
        "final_score = correct_labels / total_labels * 100 if total_labels else 0\n",
        "print(f\"Final Score: {final_score:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b193c7c6",
      "metadata": {
        "id": "b193c7c6"
      },
      "source": [
        "# Subnarrative Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "b87b700e001a0c73",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:17:55.105319Z",
          "start_time": "2025-01-01T13:17:55.100817Z"
        },
        "id": "b87b700e001a0c73"
      },
      "outputs": [],
      "source": [
        "class SubNarrativeClassificationModel(PreTrainedModel):\n",
        "    def __init__(self, pretrained_model_name, num_sub_narrative_labels):\n",
        "        config = AutoConfig.from_pretrained(pretrained_model_name)\n",
        "        config.num_labels = num_sub_narrative_labels\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.bert = AutoModel.from_pretrained(pretrained_model_name)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, config.num_labels)\n",
        "        self.loss_fn = BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = self.classifier(outputs.last_hidden_state[:, 0, :])  # Use [CLS] token embeddings\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "\n",
        "        return SequenceClassifierOutput(loss=loss, logits=logits)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lxtrSDQC89WQ",
      "metadata": {
        "id": "lxtrSDQC89WQ"
      },
      "source": [
        "### **Subnarratives (Without Narrative Context)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "Cs9vK3b_9JKp",
      "metadata": {
        "id": "Cs9vK3b_9JKp"
      },
      "outputs": [],
      "source": [
        "# Create subnarrative datasets\n",
        "train_sub_narrative_dataset = NarrativeDataset(\n",
        "    train_texts.tolist(), y_train_sub, None, tokenizer, max_len\n",
        ")\n",
        "val_sub_narrative_dataset = NarrativeDataset(\n",
        "    val_texts.tolist(), y_val_sub, None, tokenizer, max_len\n",
        ")\n",
        "test_sub_narrative_dataset = NarrativeDataset(\n",
        "    test_texts.tolist(), y_test_sub, None, tokenizer, max_len\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "s78CcXN2KkFb",
      "metadata": {
        "id": "s78CcXN2KkFb"
      },
      "outputs": [],
      "source": [
        "# Create subnarrative model\n",
        "sub_narrative_model_baseline = SubNarrativeClassificationModel(\n",
        "    pretrained_model_name,\n",
        "    num_sub_narrative_labels=y_train_sub.shape[1],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "aMmRNkhQ9enn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "aMmRNkhQ9enn",
        "outputId": "0dffd163-3ca4-40d1-83cd-e87febf4ecbc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1600' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1600/1600 28:10, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.166100</td>\n",
              "      <td>0.158631</td>\n",
              "      <td>0.969158</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.125220</td>\n",
              "      <td>0.968342</td>\n",
              "      <td>0.012115</td>\n",
              "      <td>0.013216</td>\n",
              "      <td>0.012641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.107900</td>\n",
              "      <td>0.113849</td>\n",
              "      <td>0.969158</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.103900</td>\n",
              "      <td>0.104700</td>\n",
              "      <td>0.970788</td>\n",
              "      <td>0.177313</td>\n",
              "      <td>0.061674</td>\n",
              "      <td>0.087355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.086600</td>\n",
              "      <td>0.104337</td>\n",
              "      <td>0.970788</td>\n",
              "      <td>0.233480</td>\n",
              "      <td>0.092511</td>\n",
              "      <td>0.120745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.079500</td>\n",
              "      <td>0.097773</td>\n",
              "      <td>0.970516</td>\n",
              "      <td>0.172745</td>\n",
              "      <td>0.118943</td>\n",
              "      <td>0.127999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.077500</td>\n",
              "      <td>0.097855</td>\n",
              "      <td>0.969565</td>\n",
              "      <td>0.238815</td>\n",
              "      <td>0.105727</td>\n",
              "      <td>0.129265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.069000</td>\n",
              "      <td>0.093911</td>\n",
              "      <td>0.970109</td>\n",
              "      <td>0.262315</td>\n",
              "      <td>0.136564</td>\n",
              "      <td>0.161770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.060700</td>\n",
              "      <td>0.092508</td>\n",
              "      <td>0.969837</td>\n",
              "      <td>0.256891</td>\n",
              "      <td>0.145374</td>\n",
              "      <td>0.176627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.055000</td>\n",
              "      <td>0.093182</td>\n",
              "      <td>0.969158</td>\n",
              "      <td>0.233407</td>\n",
              "      <td>0.149780</td>\n",
              "      <td>0.166670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.048400</td>\n",
              "      <td>0.093016</td>\n",
              "      <td>0.970109</td>\n",
              "      <td>0.298825</td>\n",
              "      <td>0.127753</td>\n",
              "      <td>0.163052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.050100</td>\n",
              "      <td>0.091669</td>\n",
              "      <td>0.970380</td>\n",
              "      <td>0.416195</td>\n",
              "      <td>0.185022</td>\n",
              "      <td>0.221557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.042800</td>\n",
              "      <td>0.090769</td>\n",
              "      <td>0.970652</td>\n",
              "      <td>0.321566</td>\n",
              "      <td>0.167401</td>\n",
              "      <td>0.204672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.038300</td>\n",
              "      <td>0.091294</td>\n",
              "      <td>0.970924</td>\n",
              "      <td>0.354494</td>\n",
              "      <td>0.185022</td>\n",
              "      <td>0.224550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.093453</td>\n",
              "      <td>0.971467</td>\n",
              "      <td>0.454699</td>\n",
              "      <td>0.176211</td>\n",
              "      <td>0.227206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.035800</td>\n",
              "      <td>0.093609</td>\n",
              "      <td>0.970245</td>\n",
              "      <td>0.399944</td>\n",
              "      <td>0.193833</td>\n",
              "      <td>0.227537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.036600</td>\n",
              "      <td>0.091874</td>\n",
              "      <td>0.969973</td>\n",
              "      <td>0.364005</td>\n",
              "      <td>0.171806</td>\n",
              "      <td>0.217761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.031300</td>\n",
              "      <td>0.091409</td>\n",
              "      <td>0.971060</td>\n",
              "      <td>0.446366</td>\n",
              "      <td>0.193833</td>\n",
              "      <td>0.248422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.028800</td>\n",
              "      <td>0.093254</td>\n",
              "      <td>0.970245</td>\n",
              "      <td>0.425131</td>\n",
              "      <td>0.180617</td>\n",
              "      <td>0.223105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.033100</td>\n",
              "      <td>0.092798</td>\n",
              "      <td>0.970652</td>\n",
              "      <td>0.412487</td>\n",
              "      <td>0.185022</td>\n",
              "      <td>0.229543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1600, training_loss=0.07053177824243903, metrics={'train_runtime': 1690.8764, 'train_samples_per_second': 7.558, 'train_steps_per_second': 0.946, 'total_flos': 3365276483174400.0, 'train_loss': 0.07053177824243903, 'epoch': 20.0})"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create subnarrative model trainer\n",
        "sub_narrative_baseline_trainer = Trainer(\n",
        "    model=sub_narrative_model_baseline,\n",
        "    args=training_args,\n",
        "    train_dataset=train_sub_narrative_dataset,\n",
        "    eval_dataset=val_sub_narrative_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Training the second layer model\n",
        "sub_narrative_baseline_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "vACkM1NkIo74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "vACkM1NkIo74",
        "outputId": "e29f1af9-4bdf-48a5-d6fa-1d7df2f36b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.07413209974765778,\n",
              " 'eval_accuracy': 0.9767663043478261,\n",
              " 'eval_precision': 0.3178451982799809,\n",
              " 'eval_recall': 0.21195652173913043,\n",
              " 'eval_f1': 0.24643466082085008,\n",
              " 'eval_runtime': 2.3902,\n",
              " 'eval_samples_per_second': 33.47,\n",
              " 'eval_steps_per_second': 4.184,\n",
              " 'epoch': 20.0}"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "print(\"Evaluating on test set...\")\n",
        "results = sub_narrative_baseline_trainer.evaluate(test_sub_narrative_dataset)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "tXhW6-GQI1XR",
      "metadata": {
        "id": "tXhW6-GQI1XR"
      },
      "outputs": [],
      "source": [
        "# Save narrative model for more downstream use\n",
        "with open('sub_narrative_model_baseline.pkl','wb') as f:\n",
        "    pickle.dump(sub_narrative_model_baseline,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "PP11aWYqI1sh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "PP11aWYqI1sh",
        "outputId": "764e01b8-d42c-483b-f3e3-81adaf4c8dcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.07413209974765778,\n",
              " 'eval_model_preparation_time': 0.0031,\n",
              " 'eval_accuracy': 0.9767663043478261,\n",
              " 'eval_precision': 0.3178451982799809,\n",
              " 'eval_recall': 0.21195652173913043,\n",
              " 'eval_f1': 0.24643466082085008,\n",
              " 'eval_runtime': 2.4615,\n",
              " 'eval_samples_per_second': 32.501,\n",
              " 'eval_steps_per_second': 4.063}"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sanity Check for sub_narrative_model_baseline store\n",
        "\n",
        "with open('sub_narrative_model_baseline.pkl', 'rb') as f:\n",
        "    sn_model_b = pickle.load(f)\n",
        "\n",
        "sn_b_trainer = Trainer(\n",
        "    model=sn_model_b,\n",
        "    args=training_args,\n",
        "    train_dataset=train_sub_narrative_dataset,\n",
        "    eval_dataset=val_sub_narrative_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating on test set...\")\n",
        "results = sn_b_trainer.evaluate(test_sub_narrative_dataset)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hyTK12f_3hs2",
      "metadata": {
        "id": "hyTK12f_3hs2"
      },
      "source": [
        "### **Subnarratives (With Narrative Context)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "70ffc3a4ffce6366",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:17:55.820472Z",
          "start_time": "2025-01-01T13:17:55.816766Z"
        },
        "id": "70ffc3a4ffce6366"
      },
      "outputs": [],
      "source": [
        "def augment_input_with_narratives(texts, narrative_preds, mlb):\n",
        "    augmented_texts = []\n",
        "    for text, pred in zip(texts, narrative_preds):\n",
        "        predicted_labels = mlb.inverse_transform(pred.reshape(1, -1))[0]\n",
        "        narrative_prefix = \" \".join([f\"[Narrative: {label}]\" for label in predicted_labels])\n",
        "        augmented_text = f\"{narrative_prefix} {text}\"\n",
        "        augmented_texts.append(augmented_text)\n",
        "    return augmented_texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "29b6aa4f0995a14b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:49:38.029618Z",
          "start_time": "2025-01-01T13:49:37.316694Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "29b6aa4f0995a14b",
        "outputId": "b0e36bdb-3f84-49cf-9fe9-6f4bcffa3b20"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create augmented dataset\n",
        "threshold = 0.5\n",
        "\n",
        "# Augmenting training data with true labels\n",
        "augmented_train_texts = augment_input_with_narratives(train_texts, y_train_narratives, narrative_mlb)\n",
        "display('augmented_train_texts: ', augmented_train_texts)\n",
        "train_sub_narrative_dataset = NarrativeDataset(\n",
        "    augmented_train_texts, None, y_train_sub, tokenizer, max_len\n",
        ")\n",
        "\n",
        "# The validation set is augmented with prediction results\n",
        "val_narrative_predictions = narrative_trainer.predict(val_narrative_dataset).predictions\n",
        "val_narrative_preds = (val_narrative_predictions > threshold).astype(int)\n",
        "augmented_val_texts = augment_input_with_narratives(val_texts, val_narrative_preds, narrative_mlb)\n",
        "val_sub_narrative_dataset = NarrativeDataset(\n",
        "    augmented_val_texts, None, y_val_sub, tokenizer, max_len\n",
        ")\n",
        "\n",
        "# The test set maintains the original logic\n",
        "test_narrative_predictions = narrative_trainer.predict(test_narrative_dataset).predictions\n",
        "test_narrative_preds = (test_narrative_predictions > threshold).astype(int)\n",
        "augmented_test_texts = augment_input_with_narratives(test_texts, test_narrative_preds, narrative_mlb)\n",
        "test_sub_narrative_dataset = NarrativeDataset(\n",
        "    augmented_test_texts, None, y_test_sub, tokenizer, max_len\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "NGhTqYCsK56s",
      "metadata": {
        "id": "NGhTqYCsK56s"
      },
      "outputs": [],
      "source": [
        "# Create subnarrative model\n",
        "sub_narrative_model = SubNarrativeClassificationModel(\n",
        "    pretrained_model_name,\n",
        "    num_sub_narrative_labels=y_train_sub.shape[1],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "e08a753873a2d9e7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:50:21.135722Z",
          "start_time": "2025-01-01T13:49:39.628915Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "e08a753873a2d9e7",
        "outputId": "a9efd38b-28ab-49dd-b33f-bc420fc71885"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1600' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1600/1600 28:20, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.169200</td>\n",
              "      <td>0.162261</td>\n",
              "      <td>0.969158</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.121300</td>\n",
              "      <td>0.126673</td>\n",
              "      <td>0.968886</td>\n",
              "      <td>0.018172</td>\n",
              "      <td>0.013216</td>\n",
              "      <td>0.015303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.102500</td>\n",
              "      <td>0.114368</td>\n",
              "      <td>0.969565</td>\n",
              "      <td>0.076909</td>\n",
              "      <td>0.074890</td>\n",
              "      <td>0.075472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.098100</td>\n",
              "      <td>0.107080</td>\n",
              "      <td>0.969293</td>\n",
              "      <td>0.113769</td>\n",
              "      <td>0.127753</td>\n",
              "      <td>0.111072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.078300</td>\n",
              "      <td>0.104892</td>\n",
              "      <td>0.968886</td>\n",
              "      <td>0.168048</td>\n",
              "      <td>0.149780</td>\n",
              "      <td>0.137981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.074200</td>\n",
              "      <td>0.103988</td>\n",
              "      <td>0.968207</td>\n",
              "      <td>0.207552</td>\n",
              "      <td>0.127753</td>\n",
              "      <td>0.131948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.101634</td>\n",
              "      <td>0.969158</td>\n",
              "      <td>0.209414</td>\n",
              "      <td>0.140969</td>\n",
              "      <td>0.150289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.067800</td>\n",
              "      <td>0.101802</td>\n",
              "      <td>0.969022</td>\n",
              "      <td>0.204370</td>\n",
              "      <td>0.167401</td>\n",
              "      <td>0.165416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.061300</td>\n",
              "      <td>0.101521</td>\n",
              "      <td>0.968478</td>\n",
              "      <td>0.211576</td>\n",
              "      <td>0.193833</td>\n",
              "      <td>0.187421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.056500</td>\n",
              "      <td>0.102200</td>\n",
              "      <td>0.968342</td>\n",
              "      <td>0.252261</td>\n",
              "      <td>0.167401</td>\n",
              "      <td>0.180365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.049300</td>\n",
              "      <td>0.102649</td>\n",
              "      <td>0.969022</td>\n",
              "      <td>0.310103</td>\n",
              "      <td>0.193833</td>\n",
              "      <td>0.208994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.052300</td>\n",
              "      <td>0.103086</td>\n",
              "      <td>0.968614</td>\n",
              "      <td>0.347286</td>\n",
              "      <td>0.224670</td>\n",
              "      <td>0.239146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.043900</td>\n",
              "      <td>0.103535</td>\n",
              "      <td>0.968614</td>\n",
              "      <td>0.312632</td>\n",
              "      <td>0.185022</td>\n",
              "      <td>0.198935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.039800</td>\n",
              "      <td>0.102894</td>\n",
              "      <td>0.969022</td>\n",
              "      <td>0.327986</td>\n",
              "      <td>0.202643</td>\n",
              "      <td>0.220403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.030900</td>\n",
              "      <td>0.103462</td>\n",
              "      <td>0.968886</td>\n",
              "      <td>0.340203</td>\n",
              "      <td>0.198238</td>\n",
              "      <td>0.220500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.036300</td>\n",
              "      <td>0.104762</td>\n",
              "      <td>0.969158</td>\n",
              "      <td>0.343824</td>\n",
              "      <td>0.207048</td>\n",
              "      <td>0.225146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.036700</td>\n",
              "      <td>0.104061</td>\n",
              "      <td>0.969837</td>\n",
              "      <td>0.383893</td>\n",
              "      <td>0.229075</td>\n",
              "      <td>0.253801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.031400</td>\n",
              "      <td>0.103928</td>\n",
              "      <td>0.969973</td>\n",
              "      <td>0.386157</td>\n",
              "      <td>0.224670</td>\n",
              "      <td>0.253055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.029500</td>\n",
              "      <td>0.104728</td>\n",
              "      <td>0.969973</td>\n",
              "      <td>0.397610</td>\n",
              "      <td>0.220264</td>\n",
              "      <td>0.251384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.033400</td>\n",
              "      <td>0.104398</td>\n",
              "      <td>0.969973</td>\n",
              "      <td>0.379825</td>\n",
              "      <td>0.220264</td>\n",
              "      <td>0.248148</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1600, training_loss=0.07038670759648084, metrics={'train_runtime': 1700.9797, 'train_samples_per_second': 7.513, 'train_steps_per_second': 0.941, 'total_flos': 3365276483174400.0, 'train_loss': 0.07038670759648084, 'epoch': 20.0})"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create subnarrative model trainer\n",
        "sub_narrative_trainer = Trainer(\n",
        "    model=sub_narrative_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_sub_narrative_dataset,\n",
        "    eval_dataset=val_sub_narrative_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Training the second layer model\n",
        "sub_narrative_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "e92a453815524c89",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-01T13:50:37.897785Z",
          "start_time": "2025-01-01T13:50:37.535432Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "e92a453815524c89",
        "outputId": "fe2cc7ee-3427-4aab-b816-395217f4ed3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.08247312903404236,\n",
              " 'eval_accuracy': 0.9773097826086956,\n",
              " 'eval_precision': 0.3606323326432022,\n",
              " 'eval_recall': 0.31521739130434784,\n",
              " 'eval_f1': 0.3216928694874919,\n",
              " 'eval_runtime': 2.4115,\n",
              " 'eval_samples_per_second': 33.175,\n",
              " 'eval_steps_per_second': 4.147,\n",
              " 'epoch': 20.0}"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "print(\"Evaluating on test set...\")\n",
        "results = sub_narrative_trainer.evaluate(test_sub_narrative_dataset)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "a2e7db1bdfc5ce99",
      "metadata": {
        "id": "a2e7db1bdfc5ce99"
      },
      "outputs": [],
      "source": [
        "# Save narrative model for more downstream use\n",
        "with open('sub_narrative_model_with_augment.pkl','wb') as f:\n",
        "    pickle.dump(sub_narrative_model,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "r--hkEkG7Ddp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "r--hkEkG7Ddp",
        "outputId": "59bc48a6-8249-44ae-edda-f1b05902d231"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.08247312903404236,\n",
              " 'eval_model_preparation_time': 0.005,\n",
              " 'eval_accuracy': 0.9773097826086956,\n",
              " 'eval_precision': 0.3606323326432022,\n",
              " 'eval_recall': 0.31521739130434784,\n",
              " 'eval_f1': 0.3216928694874919,\n",
              " 'eval_runtime': 2.6632,\n",
              " 'eval_samples_per_second': 30.039,\n",
              " 'eval_steps_per_second': 3.755}"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sanity Check for sub_narrative_model_with_augment store\n",
        "\n",
        "with open('sub_narrative_model_with_augment.pkl', 'rb') as f:\n",
        "    sn_model_wa = pickle.load(f)\n",
        "\n",
        "sn_wa_trainer = Trainer(\n",
        "    model=sn_model_wa,\n",
        "    args=training_args,\n",
        "    train_dataset=train_sub_narrative_dataset,\n",
        "    eval_dataset=val_sub_narrative_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating on test set...\")\n",
        "results = sn_wa_trainer.evaluate(test_sub_narrative_dataset)\n",
        "results"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
